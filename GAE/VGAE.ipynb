{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3c0a39",
   "metadata": {},
   "source": [
    "# Variational Graph AutoEnconders\n",
    "\n",
    "How it works?\n",
    "Just like auto encoders but with a twist. Rather than representing the embedding space as a position vector, we represent it as a multivariate Gaussian.\n",
    "\n",
    "So usually the mapping of an auto encoder goes from input channel I -> embedding vector of size L. So the mapping is simply I -> L\n",
    "\n",
    "In a VAE another parallel branch is made to capture the sigma / variance of the original position vector. So the mapping goes from I -> L (mu) + L (sigma).\n",
    "\n",
    "These two layers are reparametrized so that back propagation can work and hence have a single VAE. \n",
    "\n",
    "Just like in graphs u have the autoencoder encode every node feature, here the VGAE will encode all the node features as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bd3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import VGAE\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87039472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msadi\\anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid('data','CiteSeer',transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels,512,cached=True)\n",
    "        self.conv1_5 = GCNConv(512,128,cached=True)         # cached only for transductive learning\n",
    "        self.conv_mu = GCNConv(128,out_channels,cached=True)\n",
    "        self.conv_logstd = GCNConv(128,out_channels,cached=True)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x,edge_index).relu()\n",
    "        x = self.conv1_5(x,edge_index).relu()\n",
    "        return self.conv_mu(x,edge_index), self.conv_logstd(x,edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5304ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 32\n",
    "num_features = dataset.num_features\n",
    "epochs = 1000\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features,out_channels))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge = data.train_pos_edge_index.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a283ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x, pos_edge):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x,pos_edge)\n",
    "    loss = model.recon_loss(z, pos_edge)\n",
    "    # Loss = Expected Loss + KL_Divergence Loss\n",
    "    loss = loss + (1/data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "def test(pos_edge,neg_edge,x,train_pos_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x,train_pos_index)\n",
    "    return model.test(z,pos_edge,neg_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adcffd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b317ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/VGAE_experiment_'+'32d_1000_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b26b738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, AUC: 0.8477, AP: 0.8615\n",
      "Epoch: 200, AUC: 0.8624, AP: 0.8774\n",
      "Epoch: 300, AUC: 0.8769, AP: 0.8905\n",
      "Epoch: 400, AUC: 0.8849, AP: 0.8980\n",
      "Epoch: 500, AUC: 0.8729, AP: 0.8918\n",
      "Epoch: 600, AUC: 0.8678, AP: 0.8918\n",
      "Epoch: 700, AUC: 0.8686, AP: 0.8908\n",
      "Epoch: 800, AUC: 0.8673, AP: 0.8888\n",
      "Epoch: 900, AUC: 0.8662, AP: 0.8883\n",
      "Epoch: 1000, AUC: 0.8661, AP: 0.8895\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    loss = train(model,optimizer,x,train_pos_edge)   \n",
    "    auc,ap = test(data.test_pos_edge_index,data.test_neg_edge_index,x,train_pos_edge)\n",
    "    if epoch%100==0:\n",
    "        print(\"Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}\".format(epoch,auc,ap))\n",
    "    writer.add_scalar('auc train',auc,epoch)\n",
    "    writer.add_scalar('ap train',ap,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ef512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e4ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
